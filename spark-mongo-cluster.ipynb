{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col,split\n",
    "from pyspark.ml.clustering import KMeans\n",
    "import json\n",
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- loc_lat: double (nullable = true)\n",
      " |-- loc_long: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "my_spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"myApp\") \\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://127.0.0.1/mydatabase.tweets_test\") \\\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb://127.0.0.1/mydatabase.tweets_test\") \\\n",
    "    .config(\"spark.io.compression.codec\", \"snappy\").getOrCreate() #this line's config is for solving lz4 error\n",
    "dataFrame=my_spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").load()\n",
    "dataFrame.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split = udf(lambda x: x.split(','))\n",
    "#df.withColumn(\"user_location\", split_udf(col(\"user_location\"))).show()\n",
    "#df=dataFrame.withColumn(\"user_location\",\n",
    "   # split(col(\"user_location\"), \",\\s*\").cast(\"array<float>\").alias(\"user_location\")\n",
    "#)\n",
    "#df_loc = df.select('user_location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['loc_lat','loc_long'],\n",
    "    outputCol='features')\n",
    "trainingData = assembler.transform(dataFrame)\n",
    "#trainingData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers: \n",
      "[60.0977304 23.9197808]\n",
      "[  37.15910751 -106.55457766]\n",
      "[ 5.49296497 98.17294613]\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(k=3,seed=1)\n",
    "model = kmeans.fit(trainingData)\n",
    "# Shows the result.\n",
    "centers = model.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster_ind = model.transform(trainingData)\n",
    "dataToKibana = cluster_ind.toPandas().to_dict('record')\n",
    "for item in dataToKibana:\n",
    "    item['created_at'] =item['created_at'][:10]+'T'+item['created_at'][11:]+'Z'\n",
    "    \n",
    "for item in dataToKibana:\n",
    "    item['loc_lat'] =round(item['loc_lat'],2)\n",
    "    item['loc_long'] =round(item['loc_long'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @TimInHonolulu: 1. Barr's usurpation of the Special Counsel authority, having already acted to give free legal advice to the President o…\n",
      "-------------\n",
      "RT @_alikingg: I just need all my girls to know that this one time I thought I was getting the flu...and it turned out to be a human. Stay…\n",
      "-------------\n",
      "I need gfs that like dressing cute and taking pics for no reason\n",
      "-------------\n",
      "RT @maddoooog: please be careful with me. sometimes i just get sad and i don't know why. i'm sorry.\n",
      "-------------\n",
      "RT @crushcuIture: it’s scary knowing that i probably wont be alive to have kids or grow old together with someone because of the fact that…\n",
      "-------------\n",
      "@MysticDreamer20 @EdBoscoVA I know right? He is the best!.\n",
      "\n",
      "And Edward, wherever you are. I love your voice of 18-Volt raps!\n",
      "-------------\n",
      "@BookLuster order in your favorite food and maybe call a close friend\n",
      "-------------\n",
      "someone wrote tsukki and yamaguchi going to different schools in this fic and they wrote how it changed tsukki's en… https://t.co/2B9idlLO86\n",
      "-------------\n",
      "RT @natvanlis: Finally picked up @Karamo’s book and absolutely love this quote from his grandmother:\n",
      "\n",
      "“Never be afraid of growing slowly, o…\n",
      "-------------\n",
      "#TLD @thelongestdate @senzgp #thelongestdate @SABC3 \n",
      "can we please have a Longest Date rematch?\n",
      "Senzo and Shalance\n",
      "Tamryn and Nathaneal\n",
      "-------------\n",
      "RT @JayInslee: Our children and grandchildren's future is worth more than millions in campaign cash from the fossil fuel industry https://t…\n",
      "-------------\n",
      "someone wrote tsukki and yamaguchi going to different schools in this fic and they wrote how it changed tsukki's en… https://t.co/2B9idlLO86\n",
      "-------------\n",
      "RT @natvanlis: Finally picked up @Karamo’s book and absolutely love this quote from his grandmother:\n",
      "\n",
      "“Never be afraid of growing slowly, o…\n",
      "-------------\n",
      "#TLD @thelongestdate @senzgp #thelongestdate @SABC3 \n",
      "can we please have a Longest Date rematch?\n",
      "Senzo and Shalance\n",
      "Tamryn and Nathaneal\n",
      "-------------\n",
      "RT @JayInslee: Our children and grandchildren's future is worth more than millions in campaign cash from the fossil fuel industry https://t…\n",
      "-------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15, [])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch(hosts='http://localhost',port=9200)\n",
    "actions = []\n",
    "mappings = {\n",
    "    \"mappings\":{\n",
    "        \"tweet\": {\n",
    "            \"properties\": {\n",
    "                \"text\": { \"type\": \"text\"  },\n",
    "                \"timestamp\": { \"type\": \"date\" },\n",
    "                \"location\": {\"type\": \"geo_point\"},\n",
    "                \"prediction\": {\"type\": \"integer\"}\n",
    "                }\n",
    "            }\n",
    "    }\n",
    "}\n",
    "es.indices.create(index=\"loc11\", body=mappings)\n",
    "for msg in dataToKibana:\n",
    "    print(msg[\"text\"])\n",
    "    print(\"-------------\")\n",
    "    action = {\n",
    "            \"index\": \"loc6\",\n",
    "            \"type\": \"tweet\",\n",
    "            \"source\": {\n",
    "                'text' : msg[\"text\"],\n",
    "                'timestamp': msg[\"created_at\"],\n",
    "                'location': {\"lat\": msg[\"loc_lat\"],\"lon\": msg[\"loc_long\"]},\n",
    "                'prediction': msg[\"prediction\"]\n",
    "                }\n",
    "            }\n",
    "    actions.append(json.dumps(action))\n",
    "helpers.bulk(es, actions, index='loc11', doc_type='tweet')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
